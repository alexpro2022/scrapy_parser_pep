# Проект: Асинхронный парсер документов PEP на базе фреймворка Scrapy.

## Оглавление
- [Технологии](#технологии)
- [Описание работы](#описание-работы)
- [Установка](#установка)
- [Запуск](#запуск-парсера)
- [Автор](#автор)


## Технологии
  - Парсинг данных (Scrapy, CSS);

[⬆️Оглавление](#оглавление)


## Описание работы
Парсер собирает ссылки на документы PEP со стартовой страницы по адресу https://peps.python.org/ 
и переходит по каждой ссылке, чтобы получить актуальную информацию о каждом PEP документе.
Парсер работает в асинхронном режиме, что существенно ускоряет выдачу результата парсинга.
Далее парсер обрабатывает информацию и выводит ее в два **.csv**-файла, уникальные названия которых имеют временную метку:
  * В первый файл выводится список [номер, название, статус] всех PEP документов.
  * Второй файл содержит сводку по статусам PEP — сколько найдено документов в каждом статусе [статус, количество документов]. В последней строке этого файла выводится итоговая информация [Total, общее количество всех документов].

[⬆️Оглавление](#оглавление)


## Установка:
1. Клонировать репозиторий с GitHub:
```
git clone git@github.com:alexpro2022/scrapy_parser_pep
```

2. Перейти в созданную директорию проекта:
```
cd scrapy_parser_pep
```

3. Создать и активировать виртуальное окружение:
```
python -m venv venv
source venv/Scripts/activate
```

4. Установить все необходимые зависимости из файла **requirements.txt**:
```
pip install -r requirements.txt
```

[⬆️Оглавление](#оглавление)


## Запуск:

```
(venv) $ scrapy crawl pep
```


## Автор
[Aleksei Proskuriakov](https://github.com/alexpro2022)

[⬆️В начало](#Проект-парсинга-pep)